MongoDB Aggregation Pipeline in Go


Run Database query with one-go

The database transaction to retrieve a large number of records in a single query is a daunting task. The millions of 
documents stored in the database have complex relationships with data nodes that require seamless flow with the software 
application service. The data node defines the business data processing workloads to perform an intensive task in real-time. 
The business software applications (Stock Market, Disaster Management, a Cryptocurrency marketplace, Census dashboard) 
require in-flight analytical data with a single database query to retrieve grouped data and a faster business transaction 
timeline. 

Techniques to handle large datasets

MongoDB provides data processing functions to analyze large datasets and produce the final aggregated results. The Map Reduce 
and Aggregation pipeline are 2 ways of aggregating, grouping, filtering data nodes in MongoDB with several functional stages.

-  What is Map-Reduce?
    Map Reduce is a javascript functional model to map documents with emit(key-value) pair based function and the reduce
    function performs the aggregation of the data node that returns the output to the client. 

    -- Structure of Map-Reduce in MongoDB
       MongoDB uses "mapReduce" database command for a collection to apply the aggregation for a query. The map-reduce 
       function faciliate to write computational logic for a data node under map function and emit the key-value result to
       reduce function for finializing the resultant document.  
       
    For example: A "mapReduce" function to count number of imdb votes for a movie stored under a collection.

    <<-- screenshot movie list -->>

    db.movies.mapReduce(
        // map
        function(){
            emit(1,this.imdb.votes);
        }, 

        // reduce
        function(key,vals){ 
            var count = 0;
            vals.forEach(function(v) {
                count +=v;
            });

            return count;
        }, 
        {  
            // query  
            query: {
                "imdb.rating": {
                    "$lt": 7.5
                }
            }, 
            // output
            out: "vote_count" 
        }
    ).find();


- What is Aggregation pipeline?

    The Aggregation pipeline works as a data processing framework in MongoDB to aggregate hierarchical data 
nodes. There will be several stages to process the documents that pass through a pipeline to filter out the 
final analyzed document. The pipeline operators used to apply logical queries and accumulate the filtered 
documents to transform an output structure. The performance of the aggregation pipeline is significantly high 
compared to Map-Reduce because the framework runs with compiled C++ codes. The data flow control works as a 
sequence of stages that the output of the previous stage becomes the input to the next stage. In each stage, 
the pipeline operator decides the type of aggregation action to perform in the database engine. 

- How to write Aggregation pipeline?
The pipeline written as BSON format passes directly into the "aggregate()" function in the Mongo Shell for 
executing the aggregation query. Also, MongoDB provides language-specific drivers that will have an in-built 
Aggregation framework with structure API functions to implement the Aggregation pipeline in the application. 

The following "aggregate" function count the total votes using aggregation pipeline. In the first stage, 
the "$match" operator applies a conditional query to filter the documents with less than 7.5 "imdb.rating". 
Then the second stage takes the filtered document as input to accumulate the $sum of "imdb.votes" and groups 
the vote_count using $group operator. 

    db.movies.aggregate(

        // Pipeline
        [
            // Stage 1
            {
                $match: {
                    // conditional query 
                    "imdb.rating": {
                        "$lt": 7.5
                    }
                }
            },

            // Stage 2
            {
                $group: {
                    _id: "total_vote",
                    vote_count: { 
                        "$sum": "$imdb.votes"
                    }
                }
            },
        ]
    );

    Analyzing Explain Plan

    The performance measurement of the aggregation query is fully analyzed using explain plan. MongoDB supports
    three type of verbosity mode than can explain a query execution plan, queryPlanner, executionStats and 
    allPlansExecution. 
    
    As an internal layer, the aggregation framework uses MongoDB Query Language (MQL) to execute the query. 
    In the process of optimizing the aggregation query database engine reorders the pipeline stages and 
    embeds the $cursor operator as the first stage of the pipeline to decide to pick the best possible 
    winning plan for stages. The winningPlan will form the metadata to make a judgment call on type document
    scan operation [IXSCAN, COLLSCAN, FETCH] on stage for faster retreival of the documents.


    Explain with queryPlanner

    db.getCollection("movies").explain("queryPlanner").aggregate(pipeline)

    "stages" : [
        {
            "$cursor" : {
                "queryPlanner" : {
                    "namespace" : "movie_details.movies", 
                    "indexFilterSet" : false, 
                    "parsedQuery" : {
                        "imdb.rating" : {
                            "$lt" : 7.5
                        }
                    }, 
                    "queryHash" : "148454AD", 
                    "planCacheKey" : "42DB0972", 
                    "maxIndexedOrSolutionsReached" : false, 
                    "maxIndexedAndSolutionsReached" : false, 
                    "maxScansToExplodeReached" : false, 
                    "winningPlan" : {
                        "stage" : "PROJECTION_DEFAULT", 
                        "transformBy" : {
                            "imdb.votes" : 1.0, 
                            "_id" : 0.0
                        }, 
                        "inputStage" : {
                            "stage" : "COLLSCAN", // scan entire collection to match with the record
                            "filter" : {
                                "imdb.rating" : {
                                    "$lt" : 7.5
                                }
                            }, 
                            "direction" : "forward"
                        }
                    }, 
                    "rejectedPlans" : [

                    ]
                }
            }
        }, 
        {
            "$group" : {
                "_id" : {
                    "$const" : "total_vote"
                }, 
                "vote_count" : {
                    "$sum" : "$imdb.votes"
                }
            }
        }
    ]

    Here the "winningPlan" stage metadata is scanned with "COLLSCAN" operation, so the entire collection data 
    nodes require to iterate all rows and records to map/match with the particular records. The COLLSCAN is 
    pretty slow and very much ineffective mapping with an enormously large data set. The queryPlanner also 
    supports indexing with IXSCAN that doesn't need to perform an entire collection scan but an index filter 
    can instantly map with a particular record.


    Explain with executionStats
    
    The statistics of winning plan query execution contains in "executionStats" mode. 
    
    db.getCollection("movies").explain("executionStats").aggregate(pipeline)

    "stages" : [

            "executionStats" : {
                    "executionSuccess" : true, 
                    "nReturned" : 18511.0, 
                    "executionTimeMillis" : 42.0, 
                    "totalKeysExamined" : 0.0, 
                    "totalDocsExamined" : 23530.0, 
                    "executionStages" : {
                        "stage" : "PROJECTION_DEFAULT", 
                        "nReturned" : 18511.0, 
                        "executionTimeMillisEstimate" : 2.0, 
                        "works" : 23532.0, 
                        "advanced" : 18511.0, 
                        "needTime" : 5020.0, 
                        "needYield" : 0.0, 
                        "saveState" : 24.0, 
                        "restoreState" : 24.0, 
                        "isEOF" : 1.0, 
                        "transformBy" : {
                            "imdb.votes" : 1.0, 
                            "_id" : 0.0
                        }, 
                        "inputStage" : {
                            "stage" : "COLLSCAN", 
                            "filter" : {
                                "imdb.rating" : {
                                    "$lt" : 7.5
                                }
                            }, 
                            "nReturned" : 18511.0, 
                            "executionTimeMillisEstimate" : 1.0, 
                            "works" : 23532.0, 
                            "advanced" : 18511.0, 
                            "needTime" : 5020.0, 
                            "needYield" : 0.0, 
                            "saveState" : 24.0, 
                            "restoreState" : 24.0, 
                            "isEOF" : 1.0, 
                            "direction" : "forward", 
                            "docsExamined" : 23530.0
                        }
                    }
                }
            }, 
            "nReturned" : NumberLong(18511), 
            "executionTimeMillisEstimate" : NumberLong(29)
    ]


    nReturned: Number of document returned from the query, in this case 18511 movies returned to the client.

    executionTimeMillis: The query execution time in millisecond that helps to understand the performance of 
    the aggregation query.

    filter: The conditional query statement included in the aggregation pipeline. 
    
    "imdb.rating" : { "$lt" : 7.5 }

    docsExamined: Total document examined in the collection to match with particular searching record

    


    Visualizing Aggregation flow in Studio 3T

    In Studio 3T, the transactional flow shows the total time to produce the result and the size of the 
    documents generated in each stage of the pipeline. The explain query in Studio 3T quite useful to 
    visualize the process for an aggregation pipeline.
    
    << -- screenshot of aggregation flow -- >>
    


